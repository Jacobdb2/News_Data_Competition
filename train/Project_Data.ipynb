{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "1. Claim and Related Article Data:\n",
    "    - Made lowercase, removed punctuations, links, unicode hex amongst other misc items like \", ', - ...etc.\n",
    "    - Removed stopwords and Tokenized\n",
    "        - To run this section, you may have to download the stopwords packages. I have included the code, you just have to uncomment 2 lines on the first run (section 1.3)\n",
    "2. Date\n",
    "    - Converted from string to datetime format (for practicality)\n",
    "    - Created 3 features:\n",
    "        - 1. Days since Jan 1st 1986\n",
    "        - 2. The Month\n",
    "        - 3. The Year\n",
    "3. Claimant\n",
    "    - Replaced missing values with \"unknown\"\n",
    "    - Replaced counts below threshold with \"other\"\n",
    "4. Final Frame\n",
    "    - 2 final frames:\n",
    "        - final_data = this is the frame that holds the claims, claimant, date, label, related articles\n",
    "        - final_articles = this is the frame that holds the related articles\n",
    "    - I have included a few extra lines of code as an example of how to work with the frames\n",
    "        - I have saved the output of the 2 dataframe to csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The following line is needed to show plots inline in notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert strings to numpy array - used to convert the related_articles column in to arrays\n",
    "# for practicality\n",
    "def str2array(value):\n",
    "    str_list = re.findall(r'\\d+', value)\n",
    "    int_list = list(map(int, str_list))\n",
    "    article_array = np.array(int_list)\n",
    "    return article_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15555, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0              NaN  17/07/2017   0      0   \n",
       "1              NaN  17/03/2018   1      2   \n",
       "2              NaN  18/07/2018   4      1   \n",
       "3              NaN  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array  \n",
       "0            [122094, 122580, 130685, 134765]  \n",
       "1                    [106868, 127320, 128060]  \n",
       "2                    [132130, 132132, 149722]  \n",
       "3                    [123254, 123418, 127464]  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column with the related articles saved as an array called \"article_array\"\n",
    "data['article_array'] = data['related_articles'].apply(str2array)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "cur_path = os.path.dirname(os.path.abspath(\"Project_Data.ipynb\"))\n",
    "articles_dir = cur_path + '/train_articles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 2.03 s, total: 4.89 s\n",
      "Wall time: 13.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131504</th>\n",
       "      <td>L'oreal abusing monkey during animal testing\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62141</th>\n",
       "      <td>Remarks by President Trump Before Marine One D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55267</th>\n",
       "      <td>Scott likes Rubio's push on immigration reform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150721</th>\n",
       "      <td>Effectiveness of fluoride in preventing caries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159743</th>\n",
       "      <td>Prisoners to get a monthly salary and a bonus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article\n",
       "131504  L'oreal abusing monkey during animal testing\\n...\n",
       "62141   Remarks by President Trump Before Marine One D...\n",
       "55267   Scott likes Rubio's push on immigration reform...\n",
       "150721  Effectiveness of fluoride in preventing caries...\n",
       "159743  Prisoners to get a monthly salary and a bonus ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create a dictionary of article ID and content\n",
    "article_dict = {}\n",
    "for filename in os.listdir(articles_dir):\n",
    "    filenumber = filename.replace('.txt', '')\n",
    "    file_open = open(articles_dir + filename, \"r\")\n",
    "    text = file_open.read()\n",
    "    article_dict[filenumber] = text\n",
    "# use the dictionary created to create a dataframe of articles\n",
    "articles  = pd.DataFrame.from_dict(article_dict, orient='index')\n",
    "articles.columns = ['Article']\n",
    "# a dataframe that holds all the articles\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Related Articles and Claim Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Cleaning for Related Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 459 ms, total: 1min 56s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CLEAN ARTICLE DATA - ~5 minutes to run\n",
    "# convert all string values to lower case\n",
    "articles_cleaned = articles.apply(lambda x: x.str.lower())\n",
    "# replace new line with space\n",
    "articles_cleaned = articles_cleaned.replace('\\n', ' ', regex=True)\n",
    "# get rid of all links\n",
    "articles_cleaned = articles_cleaned.Article.replace(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', regex = True).to_frame()\n",
    "# get rid of unicode hex\n",
    "articles_cleaned = articles_cleaned.Article.replace({r'[^\\x00-\\x7F]+':''}, regex=True).to_frame()\n",
    "# remove punctuation\n",
    "articles_cleaned = articles_cleaned.Article.str.replace('[{}]'.format(string.punctuation), '').to_frame()\n",
    "# remove misc items\n",
    "articles_cleaned = articles_cleaned.replace(' — ', ' ', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('-', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('’', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('‘', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('”', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('“', '', regex=True)\n",
    "# replace consecutive spaces with just one space\n",
    "articles_cleaned = articles_cleaned.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131504</th>\n",
       "      <td>loreal abusing monkey during animal testing da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62141</th>\n",
       "      <td>remarks by president trump before marine one d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55267</th>\n",
       "      <td>scott likes rubios push on immigration reform ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150721</th>\n",
       "      <td>effectiveness of fluoride in preventing caries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159743</th>\n",
       "      <td>prisoners to get a monthly salary and a bonus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article\n",
       "131504  loreal abusing monkey during animal testing da...\n",
       "62141   remarks by president trump before marine one d...\n",
       "55267   scott likes rubios push on immigration reform ...\n",
       "150721  effectiveness of fluoride in preventing caries...\n",
       "159743  prisoners to get a monthly salary and a bonus ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Basic Cleaning for Claims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 464 ms, sys: 3.99 ms, total: 468 ms\n",
      "Wall time: 467 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CLEAN CLAIM DATA\n",
    "# create a new dataframe of just claims\n",
    "cleaned_claim = data.claim.to_frame()\n",
    "# convert all string values to lower case\n",
    "cleaned_claim = cleaned_claim.apply(lambda x: x.str.lower())\n",
    "# replace new line with space\n",
    "cleaned_claim = cleaned_claim.replace('\\n', ' ', regex=True)\n",
    "# get rid of all links\n",
    "cleaned_claim = cleaned_claim.claim.replace(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', regex = True).to_frame()\n",
    "# get rid of unicode hex\n",
    "cleaned_claim = cleaned_claim.claim.replace({r'[^\\x00-\\x7F]+':''}, regex=True).to_frame()\n",
    "# remove punctuation\n",
    "cleaned_claim = cleaned_claim.claim.str.replace('[{}]'.format(string.punctuation), '').to_frame()\n",
    "# remove misc items\n",
    "cleaned_claim = cleaned_claim.replace(' — ', ' ', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('-', ' ', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('’', '', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('‘', '', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('”', '', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('“', '', regex=True)\n",
    "# replace consecutive spaces with just one space\n",
    "cleaned_claim = cleaned_claim.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "      <th>article_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a line from george orwells novel 1984 predicts...</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maine legislature candidate leslie gibson insu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a 17yearold girl named alyssa carson is being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1988 author roald dahl penned an open lette...</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when it comes to fighting terrorism another th...</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  label  \\\n",
       "0  a line from george orwells novel 1984 predicts...      0   \n",
       "1  maine legislature candidate leslie gibson insu...      2   \n",
       "2  a 17yearold girl named alyssa carson is being ...      1   \n",
       "3  in 1988 author roald dahl penned an open lette...      2   \n",
       "4  when it comes to fighting terrorism another th...      2   \n",
       "\n",
       "                                article_array  \n",
       "0            [122094, 122580, 130685, 134765]  \n",
       "1                    [106868, 127320, 128060]  \n",
       "2                    [132130, 132132, 149722]  \n",
       "3                    [123254, 123418, 127464]  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate cleaned_claims with label and article_array\n",
    "cleaned_claim = pd.concat([cleaned_claim, data.label, data.article_array], axis=1)\n",
    "# cleaned_claim now holds the claims that are cleaned, the label, and the article array\n",
    "cleaned_claim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Stemming, Stop Words and Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "# the first time running - you may need to uncomment the bottom two lines to download the necessary packages\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of claims\n",
    "claim_list=[]\n",
    "for i in range(cleaned_claim.shape[0]):\n",
    "    claim_entry = cleaned_claim.claim.loc[i]\n",
    "    claim_list.append(claim_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 99.99%\n",
      "CPU times: user 34.2 s, sys: 2.3 s, total: 36.5 s\n",
      "Wall time: 33.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenize every claim in the claim list generated from above\n",
    "# the result is a list of tokenized claims: tokenized_claims\n",
    "tokenized_claims = []\n",
    "stemmed_claims = []\n",
    "stemmed_sw_claims = []\n",
    "for i in range(cleaned_claim.shape[0]):\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    # stemming\n",
    "    word_tokens = word_tokenize(claim_list[i])\n",
    "    stemmed_tok_claims = []\n",
    "    for w in word_tokens:\n",
    "        stemmed_tok_claims.append(ps.stem(w))\n",
    "    stemmed_string = ' '.join(stemmed_tok_claims)\n",
    "    # stemmed_claims is a list of stemmed strings\n",
    "    stemmed_claims.append(stemmed_string)\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # remove stop words\n",
    "    stemmed_sw_string = []\n",
    "    word_tokens = word_tokenize(stemmed_claims[i])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    stemmed_sw_string = ' '.join(filtered_sentence)\n",
    "    # stemmed_sw_claims is a list of stemmed strings without stopwords\n",
    "    stemmed_sw_claims.append(stemmed_sw_string)    \n",
    "        \n",
    "    #--------------------------------------------------------------    \n",
    "    # tokenize\n",
    "    tokenized_ = word_tokenize(stemmed_sw_claims[i])\n",
    "    tokenized_claims.append(tokenized_)\n",
    "    \n",
    "    # print progress\n",
    "    progress = round((i/cleaned_claim.shape[0])*100,2)\n",
    "    clear_output(wait=True)\n",
    "    print(\"progress: \" + str(progress) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenized claims\n",
    "# tokenized_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Claims Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip together all the claim lists and create a dataframe\n",
    "zipped_claims = list(zip(stemmed_claims, stemmed_sw_claims, tokenized_claims))\n",
    "claims_ = pd.DataFrame(zipped_claims, columns = ['stemmed_claims', 'stemmed_stopword_claims', 'tokenized_claims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_claims</th>\n",
       "      <th>stemmed_stopword_claims</th>\n",
       "      <th>tokenized_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a line from georg orwel novel 1984 predict the...</td>\n",
       "      <td>line georg orwel novel 1984 predict power smar...</td>\n",
       "      <td>[line, georg, orwel, novel, 1984, predict, pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main legislatur candid lesli gibson insult par...</td>\n",
       "      <td>main legislatur candid lesli gibson insult par...</td>\n",
       "      <td>[main, legislatur, candid, lesli, gibson, insu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a 17yearold girl name alyssa carson is be trai...</td>\n",
       "      <td>17yearold girl name alyssa carson train nasa b...</td>\n",
       "      <td>[17yearold, girl, name, alyssa, carson, train,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1988 author roald dahl pen an open letter u...</td>\n",
       "      <td>1988 author roald dahl pen open letter urg par...</td>\n",
       "      <td>[1988, author, roald, dahl, pen, open, letter,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when it come to fight terror anoth thing we kn...</td>\n",
       "      <td>come fight terror anoth thing know doe work ba...</td>\n",
       "      <td>[come, fight, terror, anoth, thing, know, doe,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      stemmed_claims  \\\n",
       "0  a line from georg orwel novel 1984 predict the...   \n",
       "1  main legislatur candid lesli gibson insult par...   \n",
       "2  a 17yearold girl name alyssa carson is be trai...   \n",
       "3  in 1988 author roald dahl pen an open letter u...   \n",
       "4  when it come to fight terror anoth thing we kn...   \n",
       "\n",
       "                             stemmed_stopword_claims  \\\n",
       "0  line georg orwel novel 1984 predict power smar...   \n",
       "1  main legislatur candid lesli gibson insult par...   \n",
       "2  17yearold girl name alyssa carson train nasa b...   \n",
       "3  1988 author roald dahl pen open letter urg par...   \n",
       "4  come fight terror anoth thing know doe work ba...   \n",
       "\n",
       "                                    tokenized_claims  \n",
       "0  [line, georg, orwel, novel, 1984, predict, pow...  \n",
       "1  [main, legislatur, candid, lesli, gibson, insu...  \n",
       "2  [17yearold, girl, name, alyssa, carson, train,...  \n",
       "3  [1988, author, roald, dahl, pen, open, letter,...  \n",
       "4  [come, fight, terror, anoth, thing, know, doe,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Related Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 100.0%\n",
      "CPU times: user 31min 11s, sys: 20.9 s, total: 31min 32s\n",
      "Wall time: 31min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a list of tokenized, non-stop words articles ~ may take a few minutes to run\n",
    "tokenized_articles = []\n",
    "stemmed_art = []\n",
    "stemmed_sw_art = []\n",
    "\n",
    "for i in range(articles_cleaned.shape[0]):\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    # stemming\n",
    "    word_tokens = word_tokenize(articles_cleaned.Article[articles_cleaned.index[i]])\n",
    "    stemmed_tok_art = []\n",
    "    for w in word_tokens:\n",
    "        stemmed_tok_art.append(ps.stem(w))\n",
    "    stemmed_string = ' '.join(stemmed_tok_art)\n",
    "    # stemmed_claims is a list of stemmed strings\n",
    "    stemmed_art.append(stemmed_string)\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # remove stop words\n",
    "    stemmed_sw_string = []\n",
    "    word_tokens = word_tokenize(stemmed_art[i])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    stemmed_sw_string = ' '.join(filtered_sentence)\n",
    "    # stemmed_sw_claims is a list of stemmed strings without stopwords\n",
    "    stemmed_sw_art.append(stemmed_sw_string)    \n",
    "        \n",
    "    #--------------------------------------------------------------    \n",
    "    # tokenize\n",
    "    tokenized_ = word_tokenize(stemmed_sw_art[i])\n",
    "    tokenized_articles.append(tokenized_)\n",
    "    \n",
    "    # print progress\n",
    "    progress = round((i/articles_cleaned.shape[0])*100,2)\n",
    "    clear_output(wait=True)\n",
    "    print(\"progress: \" + str(progress) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenized related articles - below is showing only the first entry of the list\n",
    "# tokenized_articles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Related Articles DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip together all the articles and create a dataframe\n",
    "zipped_articles = list(zip(stemmed_art, stemmed_sw_art, tokenized_articles))\n",
    "articles_ = pd.DataFrame(zipped_articles, columns = ['stemmed_articles', 'stemmed_stopword_articles', 'tokenized_articles'])\n",
    "# index the articles based on article ID\n",
    "articles_.index = [articles_cleaned.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_articles</th>\n",
       "      <th>stemmed_stopword_articles</th>\n",
       "      <th>tokenized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131504</th>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>[loreal, abus, monkey, dure, anim, test, dan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62141</th>\n",
       "      <td>remark by presid trump befor marin one departu...</td>\n",
       "      <td>remark presid trump befor marin one departur s...</td>\n",
       "      <td>[remark, presid, trump, befor, marin, one, dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55267</th>\n",
       "      <td>scott like rubio push on immigr reform or at l...</td>\n",
       "      <td>scott like rubio push immigr reform least part...</td>\n",
       "      <td>[scott, like, rubio, push, immigr, reform, lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150721</th>\n",
       "      <td>effect of fluorid in prevent cari in adult to ...</td>\n",
       "      <td>effect fluorid prevent cari adult date systema...</td>\n",
       "      <td>[effect, fluorid, prevent, cari, adult, date, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159743</th>\n",
       "      <td>prison to get a monthli salari and a bonu when...</td>\n",
       "      <td>prison get monthli salari bonu done serv time ...</td>\n",
       "      <td>[prison, get, monthli, salari, bonu, done, ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         stemmed_articles  \\\n",
       "131504  loreal abus monkey dure anim test dan crespo y...   \n",
       "62141   remark by presid trump befor marin one departu...   \n",
       "55267   scott like rubio push on immigr reform or at l...   \n",
       "150721  effect of fluorid in prevent cari in adult to ...   \n",
       "159743  prison to get a monthli salari and a bonu when...   \n",
       "\n",
       "                                stemmed_stopword_articles  \\\n",
       "131504  loreal abus monkey dure anim test dan crespo y...   \n",
       "62141   remark presid trump befor marin one departur s...   \n",
       "55267   scott like rubio push immigr reform least part...   \n",
       "150721  effect fluorid prevent cari adult date systema...   \n",
       "159743  prison get monthli salari bonu done serv time ...   \n",
       "\n",
       "                                       tokenized_articles  \n",
       "131504  [loreal, abus, monkey, dure, anim, test, dan, ...  \n",
       "62141   [remark, presid, trump, befor, marin, one, dep...  \n",
       "55267   [scott, like, rubio, push, immigr, reform, lea...  \n",
       "150721  [effect, fluorid, prevent, cari, adult, date, ...  \n",
       "159743  [prison, get, monthli, salari, bonu, done, ser...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>2017-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>2018-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>2018-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>2019-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>2016-03-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0              NaN  17/07/2017   0      0   \n",
       "1              NaN  17/03/2018   1      2   \n",
       "2              NaN  18/07/2018   4      1   \n",
       "3              NaN  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array   new_date  \n",
       "0            [122094, 122580, 130685, 134765] 2017-07-17  \n",
       "1                    [106868, 127320, 128060] 2018-03-17  \n",
       "2                    [132130, 132132, 149722] 2018-07-18  \n",
       "3                    [123254, 123418, 127464] 2019-02-04  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361] 2016-03-22  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date column to datetime format\n",
    "data['new_date'] = pd.to_datetime(data['date'], dayfirst=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature with consecutive days since January 1st, 1986\n",
    "data['start_date'] = pd.to_datetime('1986-01-01', format='%Y-%m-%d')\n",
    "data['cont_days'] = (data['new_date'] - data['start_date']).dt.days\n",
    "data = data.drop(['start_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Year and Month features in to int (instead of str before), can be kept as int since it is ordinal\n",
    "\n",
    "#Year\n",
    "data['Year'] = data['new_date'].apply(lambda x: \"%d\" % (x.year))\n",
    "data['Year'] = data['Year'].astype(int)\n",
    "# Month\n",
    "data['Month'] = data['new_date'].apply(lambda x: \"%d\" % (x.month))\n",
    "data['Month'] = data['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "      <th>new_date</th>\n",
       "      <th>cont_days</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11520</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>11763</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>11886</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>11038</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0              NaN  17/07/2017   0      0   \n",
       "1              NaN  17/03/2018   1      2   \n",
       "2              NaN  18/07/2018   4      1   \n",
       "3              NaN  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array   new_date  cont_days  Year  \\\n",
       "0            [122094, 122580, 130685, 134765] 2017-07-17      11520  2017   \n",
       "1                    [106868, 127320, 128060] 2018-03-17      11763  2018   \n",
       "2                    [132130, 132132, 149722] 2018-07-18      11886  2018   \n",
       "3                    [123254, 123418, 127464] 2019-02-04      12087  2019   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361] 2016-03-22      11038  2016   \n",
       "\n",
       "   Month  \n",
       "0      7  \n",
       "1      3  \n",
       "2      7  \n",
       "3      2  \n",
       "4      3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 columns at the end show the new_date (which is the date in a date format), the continuous days, \n",
    "# the year and month\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Claimant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing claimants with \"unknown\"\n",
    "data['claimant'] = data['claimant'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group together all counts less than 100 in to Others\n",
    "claimant_count = data['claimant'].value_counts()\n",
    "value_mask = data.claimant.isin(claimant_count.index[claimant_count < 100]) \n",
    "data.loc[value_mask,'claimant'] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "      <th>new_date</th>\n",
       "      <th>cont_days</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11520</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>11763</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>11886</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>11038</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0          Unknown  17/07/2017   0      0   \n",
       "1          Unknown  17/03/2018   1      2   \n",
       "2          Unknown  18/07/2018   4      1   \n",
       "3          Unknown  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array   new_date  cont_days  Year  \\\n",
       "0            [122094, 122580, 130685, 134765] 2017-07-17      11520  2017   \n",
       "1                    [106868, 127320, 128060] 2018-03-17      11763  2018   \n",
       "2                    [132130, 132132, 149722] 2018-07-18      11886  2018   \n",
       "3                    [123254, 123418, 127464] 2019-02-04      12087  2019   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361] 2016-03-22      11038  2016   \n",
       "\n",
       "   Month  \n",
       "0      7  \n",
       "1      3  \n",
       "2      7  \n",
       "3      2  \n",
       "4      3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 final dataframes, one for the data (claims, claimant, date, label, related_articles) and another for the related articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Final Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all work done above to a single frame\n",
    "final_data = pd.concat([data.claim, cleaned_claim.claim, claims_.stemmed_claims, claims_.stemmed_stopword_claims, claims_.tokenized_claims, data.claimant, data.new_date, data.cont_days, data.Year, data.Month, cleaned_claim.label, cleaned_claim.article_array], axis=1)\n",
    "# rename columns for clarity\n",
    "final_data.columns = ['raw_claim', 'cleaned_claim', 'stemmed_claims', 'stemmed_stopword_claims', 'tokenized_claim', 'claimant', 'date', 'cont_days', 'year', 'month', 'label', 'article_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_claim</th>\n",
       "      <th>cleaned_claim</th>\n",
       "      <th>stemmed_claims</th>\n",
       "      <th>stemmed_stopword_claims</th>\n",
       "      <th>tokenized_claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>cont_days</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>label</th>\n",
       "      <th>article_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>a line from george orwells novel 1984 predicts...</td>\n",
       "      <td>a line from georg orwel novel 1984 predict the...</td>\n",
       "      <td>line georg orwel novel 1984 predict power smar...</td>\n",
       "      <td>[line, georg, orwel, novel, 1984, predict, pow...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11520</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>maine legislature candidate leslie gibson insu...</td>\n",
       "      <td>main legislatur candid lesli gibson insult par...</td>\n",
       "      <td>main legislatur candid lesli gibson insult par...</td>\n",
       "      <td>[main, legislatur, candid, lesli, gibson, insu...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>11763</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>a 17yearold girl named alyssa carson is being ...</td>\n",
       "      <td>a 17yearold girl name alyssa carson is be trai...</td>\n",
       "      <td>17yearold girl name alyssa carson train nasa b...</td>\n",
       "      <td>[17yearold, girl, name, alyssa, carson, train,...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>11886</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>in 1988 author roald dahl penned an open lette...</td>\n",
       "      <td>in 1988 author roald dahl pen an open letter u...</td>\n",
       "      <td>1988 author roald dahl pen open letter urg par...</td>\n",
       "      <td>[1988, author, roald, dahl, pen, open, letter,...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>when it comes to fighting terrorism another th...</td>\n",
       "      <td>when it come to fight terror anoth thing we kn...</td>\n",
       "      <td>come fight terror anoth thing know doe work ba...</td>\n",
       "      <td>[come, fight, terror, anoth, thing, know, doe,...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>11038</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           raw_claim  \\\n",
       "0  A line from George Orwell's novel 1984 predict...   \n",
       "1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "                                       cleaned_claim  \\\n",
       "0  a line from george orwells novel 1984 predicts...   \n",
       "1  maine legislature candidate leslie gibson insu...   \n",
       "2  a 17yearold girl named alyssa carson is being ...   \n",
       "3  in 1988 author roald dahl penned an open lette...   \n",
       "4  when it comes to fighting terrorism another th...   \n",
       "\n",
       "                                      stemmed_claims  \\\n",
       "0  a line from georg orwel novel 1984 predict the...   \n",
       "1  main legislatur candid lesli gibson insult par...   \n",
       "2  a 17yearold girl name alyssa carson is be trai...   \n",
       "3  in 1988 author roald dahl pen an open letter u...   \n",
       "4  when it come to fight terror anoth thing we kn...   \n",
       "\n",
       "                             stemmed_stopword_claims  \\\n",
       "0  line georg orwel novel 1984 predict power smar...   \n",
       "1  main legislatur candid lesli gibson insult par...   \n",
       "2  17yearold girl name alyssa carson train nasa b...   \n",
       "3  1988 author roald dahl pen open letter urg par...   \n",
       "4  come fight terror anoth thing know doe work ba...   \n",
       "\n",
       "                                     tokenized_claim         claimant  \\\n",
       "0  [line, georg, orwel, novel, 1984, predict, pow...          Unknown   \n",
       "1  [main, legislatur, candid, lesli, gibson, insu...          Unknown   \n",
       "2  [17yearold, girl, name, alyssa, carson, train,...          Unknown   \n",
       "3  [1988, author, roald, dahl, pen, open, letter,...          Unknown   \n",
       "4  [come, fight, terror, anoth, thing, know, doe,...  Hillary Clinton   \n",
       "\n",
       "        date  cont_days  year  month  label  \\\n",
       "0 2017-07-17      11520  2017      7      0   \n",
       "1 2018-03-17      11763  2018      3      2   \n",
       "2 2018-07-18      11886  2018      7      1   \n",
       "3 2019-02-04      12087  2019      2      2   \n",
       "4 2016-03-22      11038  2016      3      2   \n",
       "\n",
       "                                article_array  \n",
       "0            [122094, 122580, 130685, 134765]  \n",
       "1                    [106868, 127320, 128060]  \n",
       "2                    [132130, 132132, 149722]  \n",
       "3                    [123254, 123418, 127464]  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is equivalent to the \"train.csv\" that we were given, but cleaned with a few additional feature\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "final_data.to_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 How to work with final_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a line from george orwells novel 1984 predicts the power of smartphones'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific cleaned claim\n",
    "final_data.cleaned_claim.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'line georg orwel novel 1984 predict power smartphon'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific stemmed_stopword_claims\n",
    "final_data.stemmed_stopword_claims.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code to read elements from each article_array\n",
    "\n",
    "# # to iterate the article array\n",
    "# for i in range(final_data.shape[0]):\n",
    "#     # i iterates row by row till the end\n",
    "#     for u in range(len(final_data.article_array[i])):\n",
    "#         # u holds the index of each element, within each array. Uncomment the following to understand\n",
    "#         # print(u)\n",
    "#         art_array = final_data.article_array[i]\n",
    "#         # print specific elements of each array\n",
    "#         print(art_array[u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Related Articles Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_article_list = articles.Article.tolist()\n",
    "cleaned_article_list = articles_cleaned.Article.tolist()\n",
    "final_articles_zipped = list(zip(raw_article_list, cleaned_article_list, stemmed_art, stemmed_sw_art, tokenized_articles))\n",
    "final_articles = pd.DataFrame(final_articles_zipped, columns = ['raw_articles', 'cleaned_articles', 'stemmed_articles', 'stemmed_stopwords_articles', 'tokenized_articles'])\n",
    "final_articles.index = [articles_cleaned.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_articles</th>\n",
       "      <th>cleaned_articles</th>\n",
       "      <th>stemmed_articles</th>\n",
       "      <th>stemmed_stopwords_articles</th>\n",
       "      <th>tokenized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131504</th>\n",
       "      <td>L'oreal abusing monkey during animal testing\\n...</td>\n",
       "      <td>loreal abusing monkey during animal testing da...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>[loreal, abus, monkey, dure, anim, test, dan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62141</th>\n",
       "      <td>Remarks by President Trump Before Marine One D...</td>\n",
       "      <td>remarks by president trump before marine one d...</td>\n",
       "      <td>remark by presid trump befor marin one departu...</td>\n",
       "      <td>remark presid trump befor marin one departur s...</td>\n",
       "      <td>[remark, presid, trump, befor, marin, one, dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55267</th>\n",
       "      <td>Scott likes Rubio's push on immigration reform...</td>\n",
       "      <td>scott likes rubios push on immigration reform ...</td>\n",
       "      <td>scott like rubio push on immigr reform or at l...</td>\n",
       "      <td>scott like rubio push immigr reform least part...</td>\n",
       "      <td>[scott, like, rubio, push, immigr, reform, lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150721</th>\n",
       "      <td>Effectiveness of fluoride in preventing caries...</td>\n",
       "      <td>effectiveness of fluoride in preventing caries...</td>\n",
       "      <td>effect of fluorid in prevent cari in adult to ...</td>\n",
       "      <td>effect fluorid prevent cari adult date systema...</td>\n",
       "      <td>[effect, fluorid, prevent, cari, adult, date, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159743</th>\n",
       "      <td>Prisoners to get a monthly salary and a bonus ...</td>\n",
       "      <td>prisoners to get a monthly salary and a bonus ...</td>\n",
       "      <td>prison to get a monthli salari and a bonu when...</td>\n",
       "      <td>prison get monthli salari bonu done serv time ...</td>\n",
       "      <td>[prison, get, monthli, salari, bonu, done, ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_articles  \\\n",
       "131504  L'oreal abusing monkey during animal testing\\n...   \n",
       "62141   Remarks by President Trump Before Marine One D...   \n",
       "55267   Scott likes Rubio's push on immigration reform...   \n",
       "150721  Effectiveness of fluoride in preventing caries...   \n",
       "159743  Prisoners to get a monthly salary and a bonus ...   \n",
       "\n",
       "                                         cleaned_articles  \\\n",
       "131504  loreal abusing monkey during animal testing da...   \n",
       "62141   remarks by president trump before marine one d...   \n",
       "55267   scott likes rubios push on immigration reform ...   \n",
       "150721  effectiveness of fluoride in preventing caries...   \n",
       "159743  prisoners to get a monthly salary and a bonus ...   \n",
       "\n",
       "                                         stemmed_articles  \\\n",
       "131504  loreal abus monkey dure anim test dan crespo y...   \n",
       "62141   remark by presid trump befor marin one departu...   \n",
       "55267   scott like rubio push on immigr reform or at l...   \n",
       "150721  effect of fluorid in prevent cari in adult to ...   \n",
       "159743  prison to get a monthli salari and a bonu when...   \n",
       "\n",
       "                               stemmed_stopwords_articles  \\\n",
       "131504  loreal abus monkey dure anim test dan crespo y...   \n",
       "62141   remark presid trump befor marin one departur s...   \n",
       "55267   scott like rubio push immigr reform least part...   \n",
       "150721  effect fluorid prevent cari adult date systema...   \n",
       "159743  prison get monthli salari bonu done serv time ...   \n",
       "\n",
       "                                       tokenized_articles  \n",
       "131504  [loreal, abus, monkey, dure, anim, test, dan, ...  \n",
       "62141   [remark, presid, trump, befor, marin, one, dep...  \n",
       "55267   [scott, like, rubio, push, immigr, reform, lea...  \n",
       "150721  [effect, fluorid, prevent, cari, adult, date, ...  \n",
       "159743  [prison, get, monthli, salari, bonu, done, ser...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy to be saved to a local csv file\n",
    "final_articles2 = final_articles\n",
    "final_articles2 = final_articles2.reset_index()\n",
    "final_articles2.to_csv(\"final_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 How to work with final_articles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>level_0</th>\n",
       "      <th>raw_articles</th>\n",
       "      <th>cleaned_articles</th>\n",
       "      <th>stemmed_articles</th>\n",
       "      <th>stemmed_stopwords_articles</th>\n",
       "      <th>tokenized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>131504</td>\n",
       "      <td>L'oreal abusing monkey during animal testing\\n...</td>\n",
       "      <td>loreal abusing monkey during animal testing da...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>['loreal', 'abus', 'monkey', 'dure', 'anim', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62141</td>\n",
       "      <td>Remarks by President Trump Before Marine One D...</td>\n",
       "      <td>remarks by president trump before marine one d...</td>\n",
       "      <td>remark by presid trump befor marin one departu...</td>\n",
       "      <td>remark presid trump befor marin one departur s...</td>\n",
       "      <td>['remark', 'presid', 'trump', 'befor', 'marin'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55267</td>\n",
       "      <td>Scott likes Rubio's push on immigration reform...</td>\n",
       "      <td>scott likes rubios push on immigration reform ...</td>\n",
       "      <td>scott like rubio push on immigr reform or at l...</td>\n",
       "      <td>scott like rubio push immigr reform least part...</td>\n",
       "      <td>['scott', 'like', 'rubio', 'push', 'immigr', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>150721</td>\n",
       "      <td>Effectiveness of fluoride in preventing caries...</td>\n",
       "      <td>effectiveness of fluoride in preventing caries...</td>\n",
       "      <td>effect of fluorid in prevent cari in adult to ...</td>\n",
       "      <td>effect fluorid prevent cari adult date systema...</td>\n",
       "      <td>['effect', 'fluorid', 'prevent', 'cari', 'adul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>159743</td>\n",
       "      <td>Prisoners to get a monthly salary and a bonus ...</td>\n",
       "      <td>prisoners to get a monthly salary and a bonus ...</td>\n",
       "      <td>prison to get a monthli salari and a bonu when...</td>\n",
       "      <td>prison get monthli salari bonu done serv time ...</td>\n",
       "      <td>['prison', 'get', 'monthli', 'salari', 'bonu',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  level_0                                       raw_articles  \\\n",
       "0           0   131504  L'oreal abusing monkey during animal testing\\n...   \n",
       "1           1    62141  Remarks by President Trump Before Marine One D...   \n",
       "2           2    55267  Scott likes Rubio's push on immigration reform...   \n",
       "3           3   150721  Effectiveness of fluoride in preventing caries...   \n",
       "4           4   159743  Prisoners to get a monthly salary and a bonus ...   \n",
       "\n",
       "                                    cleaned_articles  \\\n",
       "0  loreal abusing monkey during animal testing da...   \n",
       "1  remarks by president trump before marine one d...   \n",
       "2  scott likes rubios push on immigration reform ...   \n",
       "3  effectiveness of fluoride in preventing caries...   \n",
       "4  prisoners to get a monthly salary and a bonus ...   \n",
       "\n",
       "                                    stemmed_articles  \\\n",
       "0  loreal abus monkey dure anim test dan crespo y...   \n",
       "1  remark by presid trump befor marin one departu...   \n",
       "2  scott like rubio push on immigr reform or at l...   \n",
       "3  effect of fluorid in prevent cari in adult to ...   \n",
       "4  prison to get a monthli salari and a bonu when...   \n",
       "\n",
       "                          stemmed_stopwords_articles  \\\n",
       "0  loreal abus monkey dure anim test dan crespo y...   \n",
       "1  remark presid trump befor marin one departur s...   \n",
       "2  scott like rubio push immigr reform least part...   \n",
       "3  effect fluorid prevent cari adult date systema...   \n",
       "4  prison get monthli salari bonu done serv time ...   \n",
       "\n",
       "                                  tokenized_articles  \n",
       "0  ['loreal', 'abus', 'monkey', 'dure', 'anim', '...  \n",
       "1  ['remark', 'presid', 'trump', 'befor', 'marin'...  \n",
       "2  ['scott', 'like', 'rubio', 'push', 'immigr', '...  \n",
       "3  ['effect', 'fluorid', 'prevent', 'cari', 'adul...  \n",
       "4  ['prison', 'get', 'monthli', 'salari', 'bonu',...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the csv\n",
    "aaron = pd.read_csv('final_articles.csv')\n",
    "aaron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>level_0</th>\n",
       "      <th>raw_articles</th>\n",
       "      <th>cleaned_articles</th>\n",
       "      <th>stemmed_articles</th>\n",
       "      <th>stemmed_stopwords_articles</th>\n",
       "      <th>tokenized_articles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131504</th>\n",
       "      <td>0</td>\n",
       "      <td>131504</td>\n",
       "      <td>L'oreal abusing monkey during animal testing\\n...</td>\n",
       "      <td>loreal abusing monkey during animal testing da...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>loreal abus monkey dure anim test dan crespo y...</td>\n",
       "      <td>['loreal', 'abus', 'monkey', 'dure', 'anim', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62141</th>\n",
       "      <td>1</td>\n",
       "      <td>62141</td>\n",
       "      <td>Remarks by President Trump Before Marine One D...</td>\n",
       "      <td>remarks by president trump before marine one d...</td>\n",
       "      <td>remark by presid trump befor marin one departu...</td>\n",
       "      <td>remark presid trump befor marin one departur s...</td>\n",
       "      <td>['remark', 'presid', 'trump', 'befor', 'marin'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55267</th>\n",
       "      <td>2</td>\n",
       "      <td>55267</td>\n",
       "      <td>Scott likes Rubio's push on immigration reform...</td>\n",
       "      <td>scott likes rubios push on immigration reform ...</td>\n",
       "      <td>scott like rubio push on immigr reform or at l...</td>\n",
       "      <td>scott like rubio push immigr reform least part...</td>\n",
       "      <td>['scott', 'like', 'rubio', 'push', 'immigr', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150721</th>\n",
       "      <td>3</td>\n",
       "      <td>150721</td>\n",
       "      <td>Effectiveness of fluoride in preventing caries...</td>\n",
       "      <td>effectiveness of fluoride in preventing caries...</td>\n",
       "      <td>effect of fluorid in prevent cari in adult to ...</td>\n",
       "      <td>effect fluorid prevent cari adult date systema...</td>\n",
       "      <td>['effect', 'fluorid', 'prevent', 'cari', 'adul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159743</th>\n",
       "      <td>4</td>\n",
       "      <td>159743</td>\n",
       "      <td>Prisoners to get a monthly salary and a bonus ...</td>\n",
       "      <td>prisoners to get a monthly salary and a bonus ...</td>\n",
       "      <td>prison to get a monthli salari and a bonu when...</td>\n",
       "      <td>prison get monthli salari bonu done serv time ...</td>\n",
       "      <td>['prison', 'get', 'monthli', 'salari', 'bonu',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  level_0  \\\n",
       "level_0                        \n",
       "131504            0   131504   \n",
       "62141             1    62141   \n",
       "55267             2    55267   \n",
       "150721            3   150721   \n",
       "159743            4   159743   \n",
       "\n",
       "                                              raw_articles  \\\n",
       "level_0                                                      \n",
       "131504   L'oreal abusing monkey during animal testing\\n...   \n",
       "62141    Remarks by President Trump Before Marine One D...   \n",
       "55267    Scott likes Rubio's push on immigration reform...   \n",
       "150721   Effectiveness of fluoride in preventing caries...   \n",
       "159743   Prisoners to get a monthly salary and a bonus ...   \n",
       "\n",
       "                                          cleaned_articles  \\\n",
       "level_0                                                      \n",
       "131504   loreal abusing monkey during animal testing da...   \n",
       "62141    remarks by president trump before marine one d...   \n",
       "55267    scott likes rubios push on immigration reform ...   \n",
       "150721   effectiveness of fluoride in preventing caries...   \n",
       "159743   prisoners to get a monthly salary and a bonus ...   \n",
       "\n",
       "                                          stemmed_articles  \\\n",
       "level_0                                                      \n",
       "131504   loreal abus monkey dure anim test dan crespo y...   \n",
       "62141    remark by presid trump befor marin one departu...   \n",
       "55267    scott like rubio push on immigr reform or at l...   \n",
       "150721   effect of fluorid in prevent cari in adult to ...   \n",
       "159743   prison to get a monthli salari and a bonu when...   \n",
       "\n",
       "                                stemmed_stopwords_articles  \\\n",
       "level_0                                                      \n",
       "131504   loreal abus monkey dure anim test dan crespo y...   \n",
       "62141    remark presid trump befor marin one departur s...   \n",
       "55267    scott like rubio push immigr reform least part...   \n",
       "150721   effect fluorid prevent cari adult date systema...   \n",
       "159743   prison get monthli salari bonu done serv time ...   \n",
       "\n",
       "                                        tokenized_articles  \n",
       "level_0                                                     \n",
       "131504   ['loreal', 'abus', 'monkey', 'dure', 'anim', '...  \n",
       "62141    ['remark', 'presid', 'trump', 'befor', 'marin'...  \n",
       "55267    ['scott', 'like', 'rubio', 'push', 'immigr', '...  \n",
       "150721   ['effect', 'fluorid', 'prevent', 'cari', 'adul...  \n",
       "159743   ['prison', 'get', 'monthli', 'salari', 'bonu',...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I prefer to reindex based on level_0 so that I can call each article directly as follows\n",
    "aaron.index = [aaron.level_0]\n",
    "aaron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'charterschool bill deserves action ohio senate president keith faber who is scouting a run for state auditor or attorney general in two years has a chance to demonstrate an affinity for defending ohioans against misspending and fraud by advancing a charterschool accountability bill ohio senate president keith faber who is scouting a run for state auditor or attorney general in two years has a chance to demonstrate an affinity for defending ohioans against misspending and fraud by advancing a charterschool accountability bill as it stands it appears that fabers senate is playing games with senate bill 298 a measure to ensure that charter schools are actually educating students this crucial reform legislation was oddly assigned to the senate finance committee rather than being sent to the education committee where sen peggy lehner rkettering had made it clear that shed fasttrack the bill senate minority leader joe schiavoni dboardman reasonably suspects his bill is being slotted for inaction the finance committee typically deals with state spending which sb 298 does not schiavonis bill deserves to be promptly heard by a committee revised as necessary and sent to the senate floor for a vote it aims to make certain that 39000 students attending ohios online schools are getting an education in exchange for 275 million in taxpayer subsidies it is natural to question these payments after a state audit found several eschools couldnt document that kids were doing even minimal schoolwork sb 298 includes provisions such as requiring online schools to keep accurate records that show students are participating in coursework and report that data monthly to the state a skeptic might think that faber is trying to block schiavioni an upandcoming democrat from achieving an important reform this is the second time in six months schiavoni said that one of his bills has been placed in the finance committee after lehner agreed to hold hearings the earlier bill to help youngstowns troubled school district has yet to have a hearing faber explained the finance committee assignment by saying one of the big issues in school funding is how you count kids he said yes that is a big issue especially for wellheeled gop donors who own charter schools and who have an interest in stalling reforms the charters are pushing the state to count only the number of hours offered students and not those that students actually participate in sorry but good intentions dont count taxpayers expect results faber promises the eschool attendance bill will get some hearings faber has an ideal opportunity here to show integrity in protecting children and taxpayers lehner a leader in educational accountability already has'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific cleaned article\n",
    "aaron.cleaned_articles.loc[75770].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Defining \\'reasonable compensation\\'\\nState House\\n\\nWhen Andy Sanborn started his first company, he recalls sleeping on the floor on an air mattress eating ramen noodles. Now, Sanborn owns The Draft in Concord, along with a couple of real estate companies. He won\\'t say how much money he makes, but he is outraged at the thought of the government telling him what salary is considered \"reasonable.\"\\n\\n\"Should government have the right and authority to tell people how much money they can make?\" Sanborn said. \"It\\'s insulting. If my wife works at Concord Hospital and makes $300,000 a year, no one blinks. If I make $300,000, I have to justify it to New Hampshire.\"\\n\\nFor decades, business owners have been required to calculate \"reasonable compensation\" for federal and state tax purposes. But as state legislators work to clarify those laws, the discussion about what is reasonable compensation has come to the forefront. To the chagrin of those involved in the technicalities of tax law, the discussion is intimately tied to the controversial expansion of the state\\'s interest and dividends tax to limited liability companies. Tax practitioners and politicians must walk a fine line between reforming the standards for calculating the tax deduction while not trampling on free market values.\\n\\n\"It\\'s a very personal and emotional issue,\" said David Heath, tax director at the Nashua accounting firm Melanson Heath, who supports pending legislation to clarify the laws. \"The bottom line is the determination of compensation for an individual is best determined by the business\\'s customers and the business environment in which they\\'re in, not by some governmental agency.\"\\n\\nWhen the business profits tax was created in New Hampshire in the early 1970s, the law said corporations had to pay taxes on their profits but could deduct the amount the owners reasonably took as compensation. The Supreme Court soon ruled that the \"reasonable compensation\" deduction must also apply to limited liability companies, which are set up under a different tax structure. The law fits with the general New Hampshire principle that \"active\" or earned income, is not taxed, while \"passive\" income from investments or profit is.\\n\\nThe standard of \"reasonable\" compensation was established to ensure that company owners do not pay themselves all of the company\\'s profits to avoid paying the business profits tax. (The 0.75 percent business enterprise tax, which taxes businesses\\' total wage and interest payments, was also an attempt to create fairness.)\\n\\nThe question of reasonable compensation is also part of the interest and dividends tax rules. When a corporation pays its shareholders money, that money is taxed as a dividend. But when an owner takes money out of a company, is that money a salary - and not taxed - or a profit and then a dividend, subject to both those taxes? The answer centers on whether the owner is performing work for the company, or just investing money. And that judgment has increasingly been the subject of Department of Revenue audits.\\n\\nDecision by audit\\n\\nIn 2004, the Legislature started providing more staff to the Department of Revenue Administration to do more audits, said Revenue Commissioner Kevin Clougherty. Last year, the state audited 6,000 taxpayers, up from 5,000 the previous two years. In 2006, the state did 1,000 business tax audits, though it is unclear how many total audits were done. Clougherty said in 2004 the state collected about $74 million from audits, and that number has gradually declined to about $40 million a year.\\n\\nClougherty said the department does not specifically target companies or their owners to examine whether the owner\\'s compensation is reasonable. Instead, it samples a variety of taxpayers, big and small, and examines their entire tax return. Clougherty could not say how many audits found problems with compensation. Phil Blatsos, Clougherty\\'s predecessor who served from 2003 to 2008, said under his leadership the department typically looked at compensation for about 200 to 250 taxpayers a year. (next page »)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific raw article\n",
    "aaron.raw_articles.loc[74306].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
