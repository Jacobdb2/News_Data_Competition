{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "1. Claim and Related Article Data:\n",
    "    - Made lowercase, removed punctuations, links, unicode hex amongst other misc items like \", ', - ...etc.\n",
    "    - Removed stopwords and Tokenized\n",
    "        - To run this section, you may have to download the stopwords packages. I have included the code, you just have to uncomment 2 lines on the first run (section 1.3)\n",
    "2. Date\n",
    "    - Converted from string to datetime format (for practicality)\n",
    "    - Created 3 features:\n",
    "        - 1. Days since Jan 1st 1986\n",
    "        - 2. The Month\n",
    "        - 3. The Year\n",
    "3. Claimant\n",
    "    - Replaced missing values with \"unknown\"\n",
    "    - Replaced counts below threshold with \"other\"\n",
    "4. Final Frame\n",
    "    - 2 final frames:\n",
    "        - final_data = this is the frame that holds the claims, claimant, date, label, related articles\n",
    "        - final_articles = this is the frame that holds the related articles\n",
    "    - i have included a few extra lines of code as an example of how to work with the frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The following line is needed to show plots inline in notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert strings to numpy array - used to convert the related_articles column in to arrays\n",
    "# for practicality\n",
    "def str2array(value):\n",
    "    str_list = re.findall(r'\\d+', value)\n",
    "    int_list = list(map(int, str_list))\n",
    "    article_array = np.array(int_list)\n",
    "    return article_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15555, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0              NaN  17/07/2017   0      0   \n",
       "1              NaN  17/03/2018   1      2   \n",
       "2              NaN  18/07/2018   4      1   \n",
       "3              NaN  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array  \n",
       "0            [122094, 122580, 130685, 134765]  \n",
       "1                    [106868, 127320, 128060]  \n",
       "2                    [132130, 132132, 149722]  \n",
       "3                    [123254, 123418, 127464]  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column with the related articles saved as an array called \"article_array\"\n",
    "data['article_array'] = data['related_articles'].apply(str2array)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "cur_path = os.path.dirname(os.path.abspath(\"Project_Data.ipynb\"))\n",
    "articles_dir = cur_path + '/train_articles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>Congressman Mike Rogers: Representing Michigan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70478</th>\n",
       "      <td>Ending Slavery: How We Free Today's Slaves: Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14010</th>\n",
       "      <td>Your Illinois News Radar Â» Erika Harold still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16775</th>\n",
       "      <td>1018 meadowspftexas\\n\\nEmail (excerpted), Nick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125671</th>\n",
       "      <td>FACT CHECK: Government Targeted Black Women wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article\n",
       "9423    Congressman Mike Rogers: Representing Michigan...\n",
       "70478   Ending Slavery: How We Free Today's Slaves: Ke...\n",
       "14010   Your Illinois News Radar Â» Erika Harold still ...\n",
       "16775   1018 meadowspftexas\\n\\nEmail (excerpted), Nick...\n",
       "125671  FACT CHECK: Government Targeted Black Women wi..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary of article ID and content\n",
    "article_dict = {}\n",
    "for filename in os.listdir(articles_dir):\n",
    "    filenumber = filename.replace('.txt', '')\n",
    "    file_open = open(articles_dir + filename, \"r\")\n",
    "    text = file_open.read()\n",
    "    article_dict[filenumber] = text\n",
    "# use the dictionary created to create a dataframe of articles\n",
    "articles  = pd.DataFrame.from_dict(article_dict, orient='index')\n",
    "articles.columns = ['Article']\n",
    "# a dataframe that holds all the articles\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Related Articles and Claim Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Cleaning for Related Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 605 ms, total: 1min 57s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CLEAN ARTICLE DATA - ~5 minutes to run\n",
    "# convert all string values to lower case\n",
    "articles_cleaned = articles.apply(lambda x: x.str.lower())\n",
    "# replace new line with space\n",
    "articles_cleaned = articles_cleaned.replace('\\n', ' ', regex=True)\n",
    "# get rid of all links\n",
    "articles_cleaned = articles_cleaned.Article.replace(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?Â«Â»ââââ]))', '', regex = True).to_frame()\n",
    "# get rid of unicode hex\n",
    "articles_cleaned = articles_cleaned.Article.replace({r'[^\\x00-\\x7F]+':''}, regex=True).to_frame()\n",
    "# remove punctuation\n",
    "articles_cleaned = articles_cleaned.Article.str.replace('[{}]'.format(string.punctuation), '').to_frame()\n",
    "# remove misc items\n",
    "articles_cleaned = articles_cleaned.replace(' â ', ' ', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('-', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('â', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('â', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('â', '', regex=True)\n",
    "articles_cleaned = articles_cleaned.replace('â', '', regex=True)\n",
    "# replace consecutive spaces with just one space\n",
    "articles_cleaned = articles_cleaned.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>congressman mike rogers representing michigans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70478</th>\n",
       "      <td>ending slavery how we free todays slaves kevin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14010</th>\n",
       "      <td>your illinois news radar erika harold still ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16775</th>\n",
       "      <td>1018 meadowspftexas email excerpted nick dorna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125671</th>\n",
       "      <td>fact check government targeted black women wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article\n",
       "9423    congressman mike rogers representing michigans...\n",
       "70478   ending slavery how we free todays slaves kevin...\n",
       "14010   your illinois news radar erika harold still ca...\n",
       "16775   1018 meadowspftexas email excerpted nick dorna...\n",
       "125671  fact check government targeted black women wit..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Basic Cleaning for Claims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 482 ms, sys: 57 Âµs, total: 482 ms\n",
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CLEAN CLAIM DATA\n",
    "# create a new dataframe of just claims\n",
    "cleaned_claim = data.claim.to_frame()\n",
    "# convert all string values to lower case\n",
    "cleaned_claim = cleaned_claim.apply(lambda x: x.str.lower())\n",
    "# replace new line with space\n",
    "cleaned_claim = cleaned_claim.replace('\\n', ' ', regex=True)\n",
    "# get rid of all links\n",
    "cleaned_claim = cleaned_claim.claim.replace(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?Â«Â»ââââ]))', '', regex = True).to_frame()\n",
    "# get rid of unicode hex\n",
    "cleaned_claim = cleaned_claim.claim.replace({r'[^\\x00-\\x7F]+':''}, regex=True).to_frame()\n",
    "# remove punctuation\n",
    "cleaned_claim = cleaned_claim.claim.str.replace('[{}]'.format(string.punctuation), '').to_frame()\n",
    "# remove misc items\n",
    "cleaned_claim = cleaned_claim.replace(' â ', ' ', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('-', ' ', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('â', '', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('â', '', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('â', '', regex=True)\n",
    "cleaned_claim = cleaned_claim.replace('â', '', regex=True)\n",
    "# replace consecutive spaces with just one space\n",
    "cleaned_claim = cleaned_claim.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "      <th>article_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a line from george orwells novel 1984 predicts...</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maine legislature candidate leslie gibson insu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a 17yearold girl named alyssa carson is being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1988 author roald dahl penned an open lette...</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when it comes to fighting terrorism another th...</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  label  \\\n",
       "0  a line from george orwells novel 1984 predicts...      0   \n",
       "1  maine legislature candidate leslie gibson insu...      2   \n",
       "2  a 17yearold girl named alyssa carson is being ...      1   \n",
       "3  in 1988 author roald dahl penned an open lette...      2   \n",
       "4  when it comes to fighting terrorism another th...      2   \n",
       "\n",
       "                                article_array  \n",
       "0            [122094, 122580, 130685, 134765]  \n",
       "1                    [106868, 127320, 128060]  \n",
       "2                    [132130, 132132, 149722]  \n",
       "3                    [123254, 123418, 127464]  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate cleaned_claims with label and article_array\n",
    "cleaned_claim = pd.concat([cleaned_claim, data.label, data.article_array], axis=1)\n",
    "# cleaned_claim now holds the claims that are cleaned, the label, and the article array\n",
    "cleaned_claim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Stop words and Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# the first time running - you may need to uncomment the bottom two lines to download the necessary packages\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Create a LIST of Tokenized Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of claims\n",
    "claim_list=[]\n",
    "for i in range(cleaned_claim.shape[0]):\n",
    "    claim_entry = cleaned_claim.claim.loc[i]\n",
    "    claim_list.append(claim_entry)\n",
    "\n",
    "# tokenize every claim in the claim list generated from above\n",
    "# the result is a list of tokenized claims: tokenized_claims\n",
    "tokenized_claims = []\n",
    "for i in range(cleaned_claim.shape[0]):\n",
    "    word_tokens = word_tokenize(claim_list[i])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    tokenized_claims.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenized claims\n",
    "# tokenized_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Create a LIST of Tokenized Related Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# create a list of tokenized, non-stop words articles ~ may take a few minutes to run\n",
    "tokenized_articles = []\n",
    "for i in range(articles_cleaned.shape[0]):\n",
    "    word_tokens = word_tokenize(articles_cleaned.Article[articles_cleaned.index[i]])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    tokenized_articles.append(filtered_sentence)\n",
    "    progress = round((i/articles_cleaned.shape[0])*100,2)\n",
    "    clear_output(wait=True)\n",
    "    print(\"progress: \" + str(progress) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tokenized related articles - below is showing only the first entry of the list\n",
    "# tokenized_articles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Tokenized Claims List in to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "      <th>article_array</th>\n",
       "      <th>tokenized_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a line from george orwells novel 1984 predicts...</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[line, george, orwells, novel, 1984, predicts,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maine legislature candidate leslie gibson insu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[maine, legislature, candidate, leslie, gibson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a 17yearold girl named alyssa carson is being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[17yearold, girl, named, alyssa, carson, train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1988 author roald dahl penned an open lette...</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[1988, author, roald, dahl, penned, open, lett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when it comes to fighting terrorism another th...</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[comes, fighting, terrorism, another, thing, k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  label  \\\n",
       "0  a line from george orwells novel 1984 predicts...      0   \n",
       "1  maine legislature candidate leslie gibson insu...      2   \n",
       "2  a 17yearold girl named alyssa carson is being ...      1   \n",
       "3  in 1988 author roald dahl penned an open lette...      2   \n",
       "4  when it comes to fighting terrorism another th...      2   \n",
       "\n",
       "                                article_array  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                    tokenized_claims  \n",
       "0  [line, george, orwells, novel, 1984, predicts,...  \n",
       "1  [maine, legislature, candidate, leslie, gibson...  \n",
       "2  [17yearold, girl, named, alyssa, carson, train...  \n",
       "3  [1988, author, roald, dahl, penned, open, lett...  \n",
       "4  [comes, fighting, terrorism, another, thing, k...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the tokenized claims and add it to the cleaned_claim\n",
    "tok_claims_df = pd.Series(tokenized_claims).to_frame()\n",
    "tok_claims_df.columns = ['tokenized_claims']\n",
    "cleaned_claim = pd.concat([cleaned_claim, tok_claims_df], axis=1)\n",
    "# this is the dataframe with the cleaned claim, label, article array and tokenized_claims\n",
    "cleaned_claim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conver the Tokenized Articles list in to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>tokenized_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>congressman mike rogers representing michigans...</td>\n",
       "      <td>[congressman, mike, rogers, representing, mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70478</th>\n",
       "      <td>ending slavery how we free todays slaves kevin...</td>\n",
       "      <td>[ending, slavery, free, todays, slaves, kevin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14010</th>\n",
       "      <td>your illinois news radar erika harold still ca...</td>\n",
       "      <td>[illinois, news, radar, erika, harold, still, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16775</th>\n",
       "      <td>1018 meadowspftexas email excerpted nick dorna...</td>\n",
       "      <td>[1018, meadowspftexas, email, excerpted, nick,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125671</th>\n",
       "      <td>fact check government targeted black women wit...</td>\n",
       "      <td>[fact, check, government, targeted, black, wom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article  \\\n",
       "9423    congressman mike rogers representing michigans...   \n",
       "70478   ending slavery how we free todays slaves kevin...   \n",
       "14010   your illinois news radar erika harold still ca...   \n",
       "16775   1018 meadowspftexas email excerpted nick dorna...   \n",
       "125671  fact check government targeted black women wit...   \n",
       "\n",
       "                                       tokenized_articles  \n",
       "9423    [congressman, mike, rogers, representing, mich...  \n",
       "70478   [ending, slavery, free, todays, slaves, kevin,...  \n",
       "14010   [illinois, news, radar, erika, harold, still, ...  \n",
       "16775   [1018, meadowspftexas, email, excerpted, nick,...  \n",
       "125671  [fact, check, government, targeted, black, wom...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the tokenized articles\n",
    "tok_article_df = pd.Series(tokenized_articles)\n",
    "tok_article_df.index = [articles_cleaned.index]\n",
    "tok_article_df = tok_article_df.to_frame()\n",
    "tok_article_df.columns = ['tokenized_articles']\n",
    "# reindex to combine the articles_cleaned dataframe with tok_Article_df\n",
    "articles_cleaned2 = articles_cleaned.reset_index()\n",
    "tok_article_df = tok_article_df.reset_index()\n",
    "# concatehate the two dataframes\n",
    "articles_cleaned2 = pd.concat([articles_cleaned2, tok_article_df], axis=1)\n",
    "articles_cleaned2.index = [articles_cleaned.index]\n",
    "articles_cleaned2 = articles_cleaned2.drop(['index', 'level_0'], axis=1)\n",
    "# this is the dataframe with the cleaned article and tokenized_articles, indexed by article number\n",
    "articles_cleaned2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>2017-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>2018-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>2018-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>2019-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>2016-03-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0              NaN  17/07/2017   0      0   \n",
       "1              NaN  17/03/2018   1      2   \n",
       "2              NaN  18/07/2018   4      1   \n",
       "3              NaN  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array   new_date  \n",
       "0            [122094, 122580, 130685, 134765] 2017-07-17  \n",
       "1                    [106868, 127320, 128060] 2018-03-17  \n",
       "2                    [132130, 132132, 149722] 2018-07-18  \n",
       "3                    [123254, 123418, 127464] 2019-02-04  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361] 2016-03-22  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date column to datetime format\n",
    "data['new_date'] = pd.to_datetime(data['date'], dayfirst=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature with consecutive days since January 1st, 1986\n",
    "data['start_date'] = pd.to_datetime('1986-01-01', format='%Y-%m-%d')\n",
    "data['cont_days'] = (data['new_date'] - data['start_date']).dt.days\n",
    "data = data.drop(['start_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Year and Month features in to int (instead of str before), can be kept as int since it is ordinal\n",
    "\n",
    "#Year\n",
    "data['Year'] = data['new_date'].apply(lambda x: \"%d\" % (x.year))\n",
    "data['Year'] = data['Year'].astype(int)\n",
    "# Month\n",
    "data['Month'] = data['new_date'].apply(lambda x: \"%d\" % (x.month))\n",
    "data['Month'] = data['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "      <th>new_date</th>\n",
       "      <th>cont_days</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11520</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>11763</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>11886</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>11038</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0              NaN  17/07/2017   0      0   \n",
       "1              NaN  17/03/2018   1      2   \n",
       "2              NaN  18/07/2018   4      1   \n",
       "3              NaN  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array   new_date  cont_days  Year  \\\n",
       "0            [122094, 122580, 130685, 134765] 2017-07-17      11520  2017   \n",
       "1                    [106868, 127320, 128060] 2018-03-17      11763  2018   \n",
       "2                    [132130, 132132, 149722] 2018-07-18      11886  2018   \n",
       "3                    [123254, 123418, 127464] 2019-02-04      12087  2019   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361] 2016-03-22      11038  2016   \n",
       "\n",
       "   Month  \n",
       "0      7  \n",
       "1      3  \n",
       "2      7  \n",
       "3      2  \n",
       "4      3  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 columns at the end show the new_date (which is the date in a date format), the continuous days, \n",
    "# the year and month\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Claimant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing claimants with \"unknown\"\n",
    "data['claimant'] = data['claimant'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group together all counts less than 100 in to Others\n",
    "claimant_count = data['claimant'].value_counts()\n",
    "value_mask = data.claimant.isin(claimant_count.index[claimant_count < 100]) \n",
    "data.loc[value_mask,'claimant'] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>article_array</th>\n",
       "      <th>new_date</th>\n",
       "      <th>cont_days</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>17/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11520</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>17/03/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>11763</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>18/07/2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>11886</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>04/02/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>22/03/2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>11038</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              claim  \\\n",
       "0           0  A line from George Orwell's novel 1984 predict...   \n",
       "1           1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2           2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3           3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4           4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "          claimant        date  id  label  \\\n",
       "0          Unknown  17/07/2017   0      0   \n",
       "1          Unknown  17/03/2018   1      2   \n",
       "2          Unknown  18/07/2018   4      1   \n",
       "3          Unknown  04/02/2019   5      2   \n",
       "4  Hillary Clinton  22/03/2016   6      2   \n",
       "\n",
       "                             related_articles  \\\n",
       "0            [122094, 122580, 130685, 134765]   \n",
       "1                    [106868, 127320, 128060]   \n",
       "2                    [132130, 132132, 149722]   \n",
       "3                    [123254, 123418, 127464]   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]   \n",
       "\n",
       "                                article_array   new_date  cont_days  Year  \\\n",
       "0            [122094, 122580, 130685, 134765] 2017-07-17      11520  2017   \n",
       "1                    [106868, 127320, 128060] 2018-03-17      11763  2018   \n",
       "2                    [132130, 132132, 149722] 2018-07-18      11886  2018   \n",
       "3                    [123254, 123418, 127464] 2019-02-04      12087  2019   \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361] 2016-03-22      11038  2016   \n",
       "\n",
       "   Month  \n",
       "0      7  \n",
       "1      3  \n",
       "2      7  \n",
       "3      2  \n",
       "4      3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 final dataframes, one for the data (claims, claimant, date, label, related_articles) and another for the related articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Final Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all work done above to a single frame\n",
    "final_data = pd.concat([data.claim, cleaned_claim.claim, cleaned_claim.tokenized_claims, data.claimant, data.new_date, data.cont_days, data.Year, data.Month, cleaned_claim.label, cleaned_claim.article_array], axis=1)\n",
    "# rename columns for clarity\n",
    "final_data.columns = ['raw_claim', 'cleaned_claim', 'tokenized_claim', 'claimant', 'date', 'cont_days', 'year', 'month', 'label', 'article_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_claim</th>\n",
       "      <th>cleaned_claim</th>\n",
       "      <th>tokenized_claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>cont_days</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>label</th>\n",
       "      <th>article_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td>a line from george orwells novel 1984 predicts...</td>\n",
       "      <td>[line, george, orwells, novel, 1984, predicts,...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>11520</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td>maine legislature candidate leslie gibson insu...</td>\n",
       "      <td>[maine, legislature, candidate, leslie, gibson...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>11763</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td>a 17yearold girl named alyssa carson is being ...</td>\n",
       "      <td>[17yearold, girl, named, alyssa, carson, train...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>11886</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td>in 1988 author roald dahl penned an open lette...</td>\n",
       "      <td>[1988, author, roald, dahl, penned, open, lett...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>when it comes to fighting terrorism another th...</td>\n",
       "      <td>[comes, fighting, terrorism, another, thing, k...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>11038</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           raw_claim  \\\n",
       "0  A line from George Orwell's novel 1984 predict...   \n",
       "1  Maine legislature candidate Leslie Gibson insu...   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...   \n",
       "3  In 1988 author Roald Dahl penned an open lette...   \n",
       "4  When it comes to fighting terrorism, \"Another ...   \n",
       "\n",
       "                                       cleaned_claim  \\\n",
       "0  a line from george orwells novel 1984 predicts...   \n",
       "1  maine legislature candidate leslie gibson insu...   \n",
       "2  a 17yearold girl named alyssa carson is being ...   \n",
       "3  in 1988 author roald dahl penned an open lette...   \n",
       "4  when it comes to fighting terrorism another th...   \n",
       "\n",
       "                                     tokenized_claim         claimant  \\\n",
       "0  [line, george, orwells, novel, 1984, predicts,...          Unknown   \n",
       "1  [maine, legislature, candidate, leslie, gibson...          Unknown   \n",
       "2  [17yearold, girl, named, alyssa, carson, train...          Unknown   \n",
       "3  [1988, author, roald, dahl, penned, open, lett...          Unknown   \n",
       "4  [comes, fighting, terrorism, another, thing, k...  Hillary Clinton   \n",
       "\n",
       "        date  cont_days  year  month  label  \\\n",
       "0 2017-07-17      11520  2017      7      0   \n",
       "1 2018-03-17      11763  2018      3      2   \n",
       "2 2018-07-18      11886  2018      7      1   \n",
       "3 2019-02-04      12087  2019      2      2   \n",
       "4 2016-03-22      11038  2016      3      2   \n",
       "\n",
       "                                article_array  \n",
       "0            [122094, 122580, 130685, 134765]  \n",
       "1                    [106868, 127320, 128060]  \n",
       "2                    [132130, 132132, 149722]  \n",
       "3                    [123254, 123418, 127464]  \n",
       "4  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is equivalent to the \"train.csv\" that we were given, but cleaned with a few additional feature\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a line from george orwells novel 1984 predicts the power of smartphones'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific cleaned claim\n",
    "final_data.cleaned_claim.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A line from George Orwell's novel 1984 predicts the power of smartphones.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific raw claim\n",
    "final_data.raw_claim.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code to read elements from each article_array\n",
    "\n",
    "# # to iterate the article array\n",
    "# for i in range(final_data.shape[0]):\n",
    "#     # i iterates row by row till the end\n",
    "#     for u in range(len(final_data.article_array[i])):\n",
    "#         # u holds the index of each element, within each array. Uncomment the following to understand\n",
    "#         # print(u)\n",
    "#         art_array = final_data.article_array[i]\n",
    "#         # print specific elements of each array\n",
    "#         print(art_array[u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Related Articles Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this frame holds the raw articles, cleaned articles, the tokenized version, the index is the article ID\n",
    "article_list = articles.Article.tolist()\n",
    "final_articles = pd.concat([articles_cleaned2.Article, articles_cleaned2.tokenized_articles], axis=1)\n",
    "final_articles['raw_article'] = article_list\n",
    "final_articles.columns = ['cleaned_articles', 'tokenized_articles', 'raw_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_articles</th>\n",
       "      <th>tokenized_articles</th>\n",
       "      <th>raw_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>congressman mike rogers representing michigans...</td>\n",
       "      <td>[congressman, mike, rogers, representing, mich...</td>\n",
       "      <td>Congressman Mike Rogers: Representing Michigan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70478</th>\n",
       "      <td>ending slavery how we free todays slaves kevin...</td>\n",
       "      <td>[ending, slavery, free, todays, slaves, kevin,...</td>\n",
       "      <td>Ending Slavery: How We Free Today's Slaves: Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14010</th>\n",
       "      <td>your illinois news radar erika harold still ca...</td>\n",
       "      <td>[illinois, news, radar, erika, harold, still, ...</td>\n",
       "      <td>Your Illinois News Radar Â» Erika Harold still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16775</th>\n",
       "      <td>1018 meadowspftexas email excerpted nick dorna...</td>\n",
       "      <td>[1018, meadowspftexas, email, excerpted, nick,...</td>\n",
       "      <td>1018 meadowspftexas\\n\\nEmail (excerpted), Nick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125671</th>\n",
       "      <td>fact check government targeted black women wit...</td>\n",
       "      <td>[fact, check, government, targeted, black, wom...</td>\n",
       "      <td>FACT CHECK: Government Targeted Black Women wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_articles  \\\n",
       "9423    congressman mike rogers representing michigans...   \n",
       "70478   ending slavery how we free todays slaves kevin...   \n",
       "14010   your illinois news radar erika harold still ca...   \n",
       "16775   1018 meadowspftexas email excerpted nick dorna...   \n",
       "125671  fact check government targeted black women wit...   \n",
       "\n",
       "                                       tokenized_articles  \\\n",
       "9423    [congressman, mike, rogers, representing, mich...   \n",
       "70478   [ending, slavery, free, todays, slaves, kevin,...   \n",
       "14010   [illinois, news, radar, erika, harold, still, ...   \n",
       "16775   [1018, meadowspftexas, email, excerpted, nick,...   \n",
       "125671  [fact, check, government, targeted, black, wom...   \n",
       "\n",
       "                                              raw_article  \n",
       "9423    Congressman Mike Rogers: Representing Michigan...  \n",
       "70478   Ending Slavery: How We Free Today's Slaves: Ke...  \n",
       "14010   Your Illinois News Radar Â» Erika Harold still ...  \n",
       "16775   1018 meadowspftexas\\n\\nEmail (excerpted), Nick...  \n",
       "125671  FACT CHECK: Government Targeted Black Women wi...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'defining reasonable compensation state house when andy sanborn started his first company he recalls sleeping on the floor on an air mattress eating ramen noodles now sanborn owns the draft in concord along with a couple of real estate companies he wont say how much money he makes but he is outraged at the thought of the government telling him what salary is considered reasonable should government have the right and authority to tell people how much money they can make sanborn said its insulting if my wife works at concord hospital and makes 300000 a year no one blinks if i make 300000 i have to justify it to new hampshire for decades business owners have been required to calculate reasonable compensation for federal and state tax purposes but as state legislators work to clarify those laws the discussion about what is reasonable compensation has come to the forefront to the chagrin of those involved in the technicalities of tax law the discussion is intimately tied to the controversial expansion of the states interest and dividends tax to limited liability companies tax practitioners and politicians must walk a fine line between reforming the standards for calculating the tax deduction while not trampling on free market values its a very personal and emotional issue said david heath tax director at the nashua accounting firm melanson heath who supports pending legislation to clarify the laws the bottom line is the determination of compensation for an individual is best determined by the businesss customers and the business environment in which theyre in not by some governmental agency when the business profits tax was created in new hampshire in the early 1970s the law said corporations had to pay taxes on their profits but could deduct the amount the owners reasonably took as compensation the supreme court soon ruled that the reasonable compensation deduction must also apply to limited liability companies which are set up under a different tax structure the law fits with the general new hampshire principle that active or earned income is not taxed while passive income from investments or profit is the standard of reasonable compensation was established to ensure that company owners do not pay themselves all of the companys profits to avoid paying the business profits tax the 075 percent business enterprise tax which taxes businesses total wage and interest payments was also an attempt to create fairness the question of reasonable compensation is also part of the interest and dividends tax rules when a corporation pays its shareholders money that money is taxed as a dividend but when an owner takes money out of a company is that money a salary and not taxed or a profit and then a dividend subject to both those taxes the answer centers on whether the owner is performing work for the company or just investing money and that judgment has increasingly been the subject of department of revenue audits decision by audit in 2004 the legislature started providing more staff to the department of revenue administration to do more audits said revenue commissioner kevin clougherty last year the state audited 6000 taxpayers up from 5000 the previous two years in 2006 the state did 1000 business tax audits though it is unclear how many total audits were done clougherty said in 2004 the state collected about 74 million from audits and that number has gradually declined to about 40 million a year clougherty said the department does not specifically target companies or their owners to examine whether the owners compensation is reasonable instead it samples a variety of taxpayers big and small and examines their entire tax return clougherty could not say how many audits found problems with compensation phil blatsos cloughertys predecessor who served from 2003 to 2008 said under his leadership the department typically looked at compensation for about 200 to 250 taxpayers a year next page '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific cleaned article\n",
    "final_articles.cleaned_articles.loc['74306'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Defining \\'reasonable compensation\\'\\nState House\\n\\nWhen Andy Sanborn started his first company, he recalls sleeping on the floor on an air mattress eating ramen noodles. Now, Sanborn owns The Draft in Concord, along with a couple of real estate companies. He won\\'t say how much money he makes, but he is outraged at the thought of the government telling him what salary is considered \"reasonable.\"\\n\\n\"Should government have the right and authority to tell people how much money they can make?\" Sanborn said. \"It\\'s insulting. If my wife works at Concord Hospital and makes $300,000 a year, no one blinks. If I make $300,000, I have to justify it to New Hampshire.\"\\n\\nFor decades, business owners have been required to calculate \"reasonable compensation\" for federal and state tax purposes. But as state legislators work to clarify those laws, the discussion about what is reasonable compensation has come to the forefront. To the chagrin of those involved in the technicalities of tax law, the discussion is intimately tied to the controversial expansion of the state\\'s interest and dividends tax to limited liability companies. Tax practitioners and politicians must walk a fine line between reforming the standards for calculating the tax deduction while not trampling on free market values.\\n\\n\"It\\'s a very personal and emotional issue,\" said David Heath, tax director at the Nashua accounting firm Melanson Heath, who supports pending legislation to clarify the laws. \"The bottom line is the determination of compensation for an individual is best determined by the business\\'s customers and the business environment in which they\\'re in, not by some governmental agency.\"\\n\\nWhen the business profits tax was created in New Hampshire in the early 1970s, the law said corporations had to pay taxes on their profits but could deduct the amount the owners reasonably took as compensation. The Supreme Court soon ruled that the \"reasonable compensation\" deduction must also apply to limited liability companies, which are set up under a different tax structure. The law fits with the general New Hampshire principle that \"active\" or earned income, is not taxed, while \"passive\" income from investments or profit is.\\n\\nThe standard of \"reasonable\" compensation was established to ensure that company owners do not pay themselves all of the company\\'s profits to avoid paying the business profits tax. (The 0.75 percent business enterprise tax, which taxes businesses\\' total wage and interest payments, was also an attempt to create fairness.)\\n\\nThe question of reasonable compensation is also part of the interest and dividends tax rules. When a corporation pays its shareholders money, that money is taxed as a dividend. But when an owner takes money out of a company, is that money a salary - and not taxed - or a profit and then a dividend, subject to both those taxes? The answer centers on whether the owner is performing work for the company, or just investing money. And that judgment has increasingly been the subject of Department of Revenue audits.\\n\\nDecision by audit\\n\\nIn 2004, the Legislature started providing more staff to the Department of Revenue Administration to do more audits, said Revenue Commissioner Kevin Clougherty. Last year, the state audited 6,000 taxpayers, up from 5,000 the previous two years. In 2006, the state did 1,000 business tax audits, though it is unclear how many total audits were done. Clougherty said in 2004 the state collected about $74 million from audits, and that number has gradually declined to about $40 million a year.\\n\\nClougherty said the department does not specifically target companies or their owners to examine whether the owner\\'s compensation is reasonable. Instead, it samples a variety of taxpayers, big and small, and examines their entire tax return. Clougherty could not say how many audits found problems with compensation. Phil Blatsos, Clougherty\\'s predecessor who served from 2003 to 2008, said under his leadership the department typically looked at compensation for about 200 to 250 taxpayers a year. (next page Â»)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to go to a specific raw article\n",
    "final_articles.raw_article.loc['74306'].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
